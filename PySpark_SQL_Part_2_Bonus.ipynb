{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1I_ZIei_xkY3NChMBnj0muRSj5SK-wavR",
      "authorship_tag": "ABX9TyO1j+ETlQNfF9VSawqFei3z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/selhabti/Test-Data-Engineer/blob/main/PySpark_SQL_Part_2_Bonus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_SFaquoQ72e"
      },
      "outputs": [],
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-2.3.1/spark-2.3.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.3.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark-stubs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.3.1-bin-hadoop2.7\""
      ],
      "metadata": {
        "id": "QpvnMps_RE4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession, Row\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, TimestampType, LongType, ShortType\n",
        "from pyspark.sql import SQLContext\n",
        "import pyspark.sql.functions as f\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"PySpark_SQL_Part_2\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "QhPxQooVRIqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "link = '/content/drive/MyDrive/Data_Engineer_WCS/Partially Cleaned Salary Dataset.csv'"
      ],
      "metadata": {
        "id": "_XBaMar0RUYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(link,header=True)\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "metadata": {
        "id": "zk0iiPH8RsuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sort locations by average salary for the jobs given in the dataset (rounded, sorted by salary)"
      ],
      "metadata": {
        "id": "2vfU9MbhSDjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import floor, col\n",
        "#df_states.select(\"*\", floor(col('hindex_score'))).show()\n",
        "#.orderBy('average salary', ascending=True)\\\n",
        "#                                   .withColumnRenamed(\"round(avg(Salary), 2)\",\"average salary\")\\"
      ],
      "metadata": {
        "id": "VNBa1lW74ShS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"Job Title\", \"Location\").agg(f.mean(\"Salary\"))\\\n",
        ".select(\"Job Title\", \"Location\", floor(col('avg(Salary)')))\\\n",
        ".withColumnRenamed(\"FLOOR(avg(Salary))\",\"average salary\")\\\n",
        ".orderBy('average salary', ascending=True)\\\n",
        "                                   .show(20, False)"
      ],
      "metadata": {
        "id": "ZuhqGcE2Mg-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Calculate the average salary for every job title (rounded, sorted by salary)"
      ],
      "metadata": {
        "id": "eR4n1MHp68vi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"Job Title\").agg(f.mean(\"Salary\"))\\\n",
        ".select(\"Job Title\",floor(col('avg(Salary)')))\\\n",
        ".withColumnRenamed(\"FLOOR(avg(Salary))\",\"average salary\")\\\n",
        ".orderBy('average salary', ascending=True)\\\n",
        "                                   .show(20, False)"
      ],
      "metadata": {
        "id": "ojrSObrX7IL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Calculate the average salary for every location"
      ],
      "metadata": {
        "id": "yPsaLs2s7XKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"Location\").agg(f.mean(\"Salary\"))\\\n",
        ".select(\"Location\", floor(col('avg(Salary)')))\\\n",
        ".withColumnRenamed(\"FLOOR(avg(Salary))\",\"average salary\")\\\n",
        ".orderBy('average salary', ascending=True)\\\n",
        "                                   .show(20, False)"
      ],
      "metadata": {
        "id": "wdLhBC1u7gKI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}